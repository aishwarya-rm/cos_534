{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set which prediction problem to study\n",
    "task = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == 1:\n",
    "    prediction = 'deceased'\n",
    "    df = pd.read_csv('/n/fs/fgvc/cos534/data/melanoma_allFrames.csv')\n",
    "    # dem = pd.read_csv(\"/n/fs/fgvc/cos534/data/melanoma_cohort.csv\")\n",
    "if task == 2:\n",
    "    prediction = 'deceased'\n",
    "    df = pd.read_csv('/n/fs/fgvc/cos534/data/hd_allFrames.csv')\n",
    "    # dem = pd.read_csv(\"/n/fs/fgvc/cos534/data/heart_cohort.csv\")\n",
    "if task == 3:\n",
    "    prediction = 'transplant'\n",
    "    df = pd.read_csv('/n/fs/fgvc/cos534/data/kidney_allFrames.csv')\n",
    "    # dem = pd.read_csv(\"/n/fs/fgvc/cos534/data/kidney_cohort.csv\")\n",
    "if task == 4:\n",
    "    prediction = 'ventilated'\n",
    "    df = pd.read_csv('/n/fs/fgvc/cos534/data/flu_pneum_allFrames.csv')\n",
    "    df = df.drop(columns=['vent'])\n",
    "    # dem = pd.read_csv(\"/n/fs/fgvc/cos534/data/flu_cohort.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = pd.read_csv(\"/n/fs/fgvc/mimiciv/1.0/icu/icustays.csv\")\n",
    "admissions = pd.read_csv(\"/n/fs/fgvc/mimiciv/1.0/core/admissions.csv\")\n",
    "diagnoses_icd = pd.read_csv(\"/n/fs/fgvc/mimiciv/1.0/hosp/diagnoses_icd.csv\")\n",
    "procs = pd.read_csv(\"/n/fs/fgvc/mimiciv/1.0/icu/procedureevents.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prediction == 'transplant':\n",
    "    TRANSPLANT_CODES = ['0091', '0092', '0093', '02Y', '02YA0Z0', '02YA0Z1', \n",
    "                        '02YA0Z2', '0794', '07Y', '07YM0Z0', '07YM0Z1', '07YM0Z2', \n",
    "                        '07YP0Z0', '07YP0Z1', '07YP0Z2', '0BYM0Z0', '0BYM0Z1', \n",
    "                        '0BY', '0BYC0Z0', '0BYC0Z1', '0BYC0Z2', '0BYD0Z0', '0BYD0Z1', \n",
    "                        '0BYD0Z2', '0BYF0Z0', '0BYF0Z1', '0BYF0Z2', '0BYG0Z0', '0BYG0Z1', \n",
    "                        '0BYG0Z2', '0BYH0Z0', '0BYH0Z1', '0BYH0Z2', '0BYJ0Z0', '0BYJ0Z1',\n",
    "                        '0BYJ0Z2', '0BYK0Z0', '0BYK0Z1', '0BYK0Z2', '0BYL0Z0', '0BYL0Z1', \n",
    "                        '0BYL0Z2', '0BYM0Z2', '0DY', '0DY50Z0', '0DY50Z1', '0DY50Z2', \n",
    "                        '0DY60Z0', '0DY60Z1', '0DY60Z2', '0DY80Z0', '0DY80Z1', '0DY80Z2',\n",
    "                        '0DYE0Z0', '0DYE0Z1', '0DYE0Z2', '0FY', '0FY00Z0', '0FY00Z1', \n",
    "                        '0FY00Z2', '0FYG0Z0', '0FYG0Z1', '0FYG0Z2', '0TY', '0TY00Z0',\n",
    "                        '0TY00Z1', '0TY00Z2', '0TY10Z0', '0TY10Z1', '0TY10Z2', '0UY',\n",
    "                        '0UY00Z0', '0UY00Z1', '0UY00Z2', '0UY10Z0', '0UY10Z1', '0UY10Z2', \n",
    "                        '0UY90Z0', '0UY90Z1', '0UY90Z2', '0WY', '0WY20Z0', '0WY20Z1', '0XY', \n",
    "                        '0XYJ0Z0', '0XYJ0Z1', '0XYK0Z0', '0XYK0Z1', '10Y', '10Y03ZE', \n",
    "                        '10Y03ZF', '10Y03ZG', '10Y03ZH', '10Y03ZJ', '10Y03ZK', '10Y03ZL', \n",
    "                        '10Y03ZM', '10Y03ZN', '10Y03ZP', '10Y03ZQ', '10Y03ZR', '10Y03ZS', \n",
    "                        '10Y03ZT', '10Y03ZV', '10Y03ZY', '10Y04ZE', '10Y04ZF', '10Y04ZG', \n",
    "                        '10Y04ZH', '10Y04ZJ', '10Y04ZK', '10Y04ZL', '10Y04ZM', '10Y04ZN', \n",
    "                        '10Y04ZP', '10Y04ZQ', '10Y04ZR', '10Y04ZS', '10Y04ZT', '10Y04ZV', \n",
    "                        '10Y04ZY', '10Y07ZE', '10Y07ZF', '10Y07ZG', '10Y07ZH', '10Y07ZJ', \n",
    "                        '10Y07ZK', '10Y07ZL', '10Y07ZM', '10Y07ZN', '10Y07ZP', '10Y07ZQ', \n",
    "                        '10Y07ZR', '10Y07ZS', '10Y07ZT', '10Y07ZV', '10Y07ZY', '1160', \n",
    "                        '1169', '3350', '3351', '3352', '336', '3751', '4100', '4101', \n",
    "                        '4102', '4103', '4104', '4106', '4107', '4108', '4109', '4191', \n",
    "                        '4194', '4697', '4974', '5051', '5059', '5280', '5282', '5283', \n",
    "                        '5284', '5285', '5286', '5553', '5561', '5569', '6353', '6592',\n",
    "                        '8256', '8258', '8375', '8377', '8664', '5855']\n",
    "\n",
    "    hadm_ids_w_transplants = diagnoses_icd[diagnoses_icd.icd_code.isin(TRANSPLANT_CODES)].hadm_id.unique()\n",
    "    stay_ids_w_transplants = cohort[cohort.hadm_id.isin(hadm_ids_w_transplants)].stay_id.unique()\n",
    "    df['transplant'] = 0\n",
    "    transplant_indices = df[df.stay_id.isin(stay_ids_w_transplants)].index\n",
    "    df.loc[transplant_indices, 'transplant'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prediction == 'deceased':\n",
    "    stay_to_hadm_id = dict(zip(cohort.stay_id, cohort.hadm_id))\n",
    "    hadm_id_to_death_var = dict(zip(cohort.hadm_id, admissions.deathtime))\n",
    "    stay_id_to_death_var = {stay_id: (1 if isinstance((hadm_id_to_death_var[hadm_id]), str) else 0) \\\n",
    "                            for stay_id, hadm_id in stay_to_hadm_id.items()}\n",
    "\n",
    "    df[\"deceased\"] = df[\"stay_id\"].map(stay_id_to_death_var)    \n",
    "    # df.to_csv('melanoma_allFrames_w_death.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prediction == 'ventilated':\n",
    "    vent = procs[procs['itemid'] == 225792]\n",
    "    ventilated_stay_ids = vent.stay_id.unique()\n",
    "    df['ventilated'] = 0\n",
    "\n",
    "    ventilated_indices = df[df.stay_id.isin(ventilated_stay_ids)].index\n",
    "    df.loc[ventilated_indices, 'ventilated'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ethnicity, marital status, insurance\n",
    "df_subject_ids = cohort[cohort.stay_id.isin(df.stay_id.unique())].subject_id.unique()\n",
    "\n",
    "stay_to_sub_id_dict = dict()\n",
    "for sid in df.stay_id.unique():\n",
    "    stay_to_sub_id_dict[sid] = cohort[cohort.stay_id == sid].subject_id.unique()[0]\n",
    "\n",
    "sub_id_to_race_dict = dict()\n",
    "sub_id_to_marital_stat_dict = dict()\n",
    "sub_id_to_insurance_dict = dict()\n",
    "\n",
    "for sid in df_subject_ids:\n",
    "    sub_id_to_race_dict[sid] = admissions[admissions.subject_id == sid].ethnicity.unique()[0]\n",
    "    sub_id_to_marital_stat_dict[sid] = admissions[admissions.subject_id == sid].marital_status.unique()[0]\n",
    "    sub_id_to_insurance_dict[sid] = admissions[admissions.subject_id == sid].insurance.unique()[0]\n",
    "\n",
    "df['subject_id'] = df[\"stay_id\"].map(stay_to_sub_id_dict)\n",
    "df['ethnicity'] = df[\"subject_id\"].map(sub_id_to_race_dict)\n",
    "df['marital_status'] = df[\"subject_id\"].map(sub_id_to_marital_stat_dict)\n",
    "df['insurance'] = df[\"subject_id\"].map(sub_id_to_insurance_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a binary classifier (gradient boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_COLS = ['anchor_age', 'patientweight', 'los', 'gender',\n",
    "       'alb', 'aniongap', 'bun', 'crp', 'ca', 'chloride', 'creatinine',\n",
    "       'fibrinogen', 'glucose', 'hgb', 'k', 'mg', 'na', 'p', 'platelets',\n",
    "       'troponin', 'wbc', 'apneainterval', 'artco2p', 'arto2p', 'expratio',\n",
    "       'hr', 'inspratio', 'insptime', 'nibpd', 'nibpm', 'nibps', 'pip', 'rr',\n",
    "       'spo2', 'temp', 'urine', 'vm', 'vt', 'betablockers', 'ca-iv',\n",
    "       'ca-noniv', 'cablockers', 'dextrose', 'fluids', 'insulin', 'k-iv',\n",
    "       'hours-k-iv', 'loopdiuretics', 'mg-iv', 'mg-noniv', 'hours-mg-noniv',\n",
    "       'p-iv', 'p-noniv', 'pnutrition', 'ponutrition', 'packedrbc',\n",
    "       'paralytics', 'sedation', 'tpnutrition', 'vasoactive', 'vasopressors',\n",
    "       'hours-p-iv']\n",
    "\n",
    "pred_var = prediction\n",
    "\n",
    "X = df[TRAIN_COLS]\n",
    "X = X.fillna(-1)\n",
    "y = df[pred_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1810, 62) (259, 62) (518, 62)\n",
      "(1810, 69) (259, 69) (518, 69)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train(70%)/validation(10%)/test(20%)\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.125, random_state=0)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "df_trainval, df_test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "df_train, df_val = train_test_split(df_trainval, test_size=0.125, random_state=0)\n",
    "print(df_train.shape, df_val.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of positive outcome: 3.65\n"
     ]
    }
   ],
   "source": [
    "# Percentage of positive outcome (calculated on the training set)\n",
    "print('% of positive outcome: {:.2f}'.format(y_train.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct a hyperparameter search and find the best set of hyperparameters\n",
    "if False: \n",
    "    param_grid = {\n",
    "        'max_depth': [10, 50, 100],\n",
    "        'min_samples_split': [2, 4, 8],\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': np.logspace(-4, 0, 10),\n",
    "    }\n",
    "\n",
    "    estimator = GradientBoostingClassifier(n_estimators=50, random_state=0)\n",
    "    clf = GridSearchCV(estimator=estimator, param_grid=param_grid)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    clf.score(X_test, y_test)\n",
    "\n",
    "# Use the best set of hyperparameters\n",
    "else:\n",
    "    optimal_params = {'learning_rate': 0.359, \n",
    "                      'max_depth': 10,\n",
    "                      'n_estimators': 50,\n",
    "                      'min_samples_split': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier with a particular random seed\n",
    "optimal_params['random_state'] = 0\n",
    "clf = GradientBoostingClassifier(**optimal_params).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on the test set\n",
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.84\n",
      "Precision: 80.00\n",
      "Recall: 88.89\n"
     ]
    }
   ],
   "source": [
    "# Calculate overall accuracy, precision, and recall\n",
    "print('Accuracy: {:.2f}'.format(sklearn.metrics.accuracy_score(y_test, pred)*100))\n",
    "print('Precision: {:.2f}'.format(sklearn.metrics.precision_score(y_test, pred)*100))\n",
    "print('Recall: {:.2f}'.format(sklearn.metrics.recall_score(y_test, pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate various metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = 'ethnicity'; group2 = 'gender'\n",
    "groups1 = ['AMERICAN INDIAN/ALASKA NATIVE', 'ASIAN', 'BLACK/AFRICAN AMERICAN',\n",
    "           'HISPANIC/LATINO', 'WHITE']\n",
    "groups2 = set(df_test[group2])\n",
    "if np.nan in groups2: groups2.remove(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AMERICAN INDIAN/ALASKA NATIVE 0\n",
      "- Count 0\n",
      "- TP 0, FP 0, TN 0, FN 0\n",
      "- Accuracy nan\n",
      "- PPV nan\n",
      "- TPR nan\n",
      "- FPR nan\n",
      "- FNR nan\n",
      "- GT positive outcome (train) nan\n",
      "- GT positive outcome (test) nan\n",
      "- Predicted positive outcome (test) nan\n",
      "- Bias amplification nan\n",
      "\n",
      "AMERICAN INDIAN/ALASKA NATIVE 1\n",
      "- Count 0\n",
      "- TP 0, FP 0, TN 0, FN 0\n",
      "- Accuracy nan\n",
      "- PPV nan\n",
      "- TPR nan\n",
      "- FPR nan\n",
      "- FNR nan\n",
      "- GT positive outcome (train) nan\n",
      "- GT positive outcome (test) nan\n",
      "- Predicted positive outcome (test) nan\n",
      "- Bias amplification nan\n",
      "\n",
      "ASIAN 0\n",
      "- Count 0\n",
      "- TP 0, FP 0, TN 0, FN 0\n",
      "- Accuracy nan\n",
      "- PPV nan\n",
      "- TPR nan\n",
      "- FPR nan\n",
      "- FNR nan\n",
      "- GT positive outcome (train) nan\n",
      "- GT positive outcome (test) nan\n",
      "- Predicted positive outcome (test) nan\n",
      "- Bias amplification nan\n",
      "\n",
      "ASIAN 1\n",
      "- Count 0\n",
      "- TP 0, FP 0, TN 0, FN 0\n",
      "- Accuracy nan\n",
      "- PPV nan\n",
      "- TPR nan\n",
      "- FPR nan\n",
      "- FNR nan\n",
      "- GT positive outcome (train) 0.00\n",
      "- GT positive outcome (test) nan\n",
      "- Predicted positive outcome (test) nan\n",
      "- Bias amplification nan\n",
      "\n",
      "BLACK/AFRICAN AMERICAN 0\n",
      "- Count 1\n",
      "- TP 0, FP 0, TN 1, FN 0\n",
      "- Accuracy 100.00\n",
      "- PPV nan\n",
      "- TPR nan\n",
      "- FPR 0.00\n",
      "- FNR nan\n",
      "- GT positive outcome (train) 0.00\n",
      "- GT positive outcome (test) 0.00\n",
      "- Predicted positive outcome (test) 0.00\n",
      "- Bias amplification 0.00\n",
      "\n",
      "BLACK/AFRICAN AMERICAN 1\n",
      "- Count 4\n",
      "- TP 0, FP 0, TN 4, FN 0\n",
      "- Accuracy 100.00\n",
      "- PPV nan\n",
      "- TPR nan\n",
      "- FPR 0.00\n",
      "- FNR nan\n",
      "- GT positive outcome (train) 0.00\n",
      "- GT positive outcome (test) 0.00\n",
      "- Predicted positive outcome (test) 0.00\n",
      "- Bias amplification 0.00\n",
      "\n",
      "HISPANIC/LATINO 0\n",
      "- Count 2\n",
      "- TP 0, FP 0, TN 2, FN 0\n",
      "- Accuracy 100.00\n",
      "- PPV nan\n",
      "- TPR nan\n",
      "- FPR 0.00\n",
      "- FNR nan\n",
      "- GT positive outcome (train) 0.00\n",
      "- GT positive outcome (test) 0.00\n",
      "- Predicted positive outcome (test) 0.00\n",
      "- Bias amplification 0.00\n",
      "\n",
      "HISPANIC/LATINO 1\n",
      "- Count 1\n",
      "- TP 0, FP 0, TN 1, FN 0\n",
      "- Accuracy 100.00\n",
      "- PPV nan\n",
      "- TPR nan\n",
      "- FPR 0.00\n",
      "- FNR nan\n",
      "- GT positive outcome (train) 0.00\n",
      "- GT positive outcome (test) 0.00\n",
      "- Predicted positive outcome (test) 0.00\n",
      "- Bias amplification 0.00\n",
      "\n",
      "WHITE 0\n",
      "- Count 323\n",
      "- TP 10, FP 2, TN 310, FN 1\n",
      "- Accuracy 99.07\n",
      "- PPV 83.33\n",
      "- TPR 90.91\n",
      "- FPR 0.64\n",
      "- FNR 9.09\n",
      "- GT positive outcome (train) 3.43\n",
      "- GT positive outcome (test) 3.41\n",
      "- Predicted positive outcome (test) 3.72\n",
      "- Bias amplification -0.29\n",
      "\n",
      "WHITE 1\n",
      "- Count 144\n",
      "- TP 5, FP 0, TN 139, FN 0\n",
      "- Accuracy 100.00\n",
      "- PPV 100.00\n",
      "- TPR 100.00\n",
      "- FPR 0.00\n",
      "- FNR 0.00\n",
      "- GT positive outcome (train) 3.85\n",
      "- GT positive outcome (test) 3.47\n",
      "- Predicted positive outcome (test) 3.47\n",
      "- Bias amplification -0.38\n"
     ]
    }
   ],
   "source": [
    "empty = 0\n",
    "for g1 in sorted(groups1):\n",
    "    for g2 in sorted(groups2):\n",
    "    \n",
    "        idx = np.logical_and(df_test[group1]==g1, df_test[group2]==g2)\n",
    "        count = idx.sum()\n",
    "        empty += count\n",
    "        baserate = y_test[idx].mean()*100\n",
    "     \n",
    "        # Calculate various metrics\n",
    "        tp = np.logical_and(y_test[idx]==1, pred[idx]==1).sum()\n",
    "        fp = np.logical_and(y_test[idx]==0, pred[idx]==1).sum()\n",
    "        tn = np.logical_and(y_test[idx]==0, pred[idx]==0).sum()\n",
    "        fn = np.logical_and(y_test[idx]==1, pred[idx]==0).sum()\n",
    "        accuracy = (tp+tn)/(tp+fp+tn+fn) * 100\n",
    "        ppv = tp/(tp+fp) * 100 # precision, used to calculate predictive parity\n",
    "        tpr = tp/(tp+fn) * 100 # recall, also used to calculate equalized opportunity and odds \n",
    "        fpr = fp/(fp+tn) * 100 # used to calculate equalized odds\n",
    "        fnr = fn/(fn+tp) * 100 # used to calculate equalized odds\n",
    "        po = (tp+fp)/(tp+fp+tn+fn) * 100 # used to calculate demographic parity\n",
    "    \n",
    "        # Calculate bias amplification\n",
    "        idx_train = np.logical_and(df_train[group1]==g1, df_train[group2]==g2)\n",
    "        delta = (pred[idx]==1).mean() - (y_train[idx_train]==1).mean()\n",
    "        ind = np.logical_and(idx_train, y_train==1).mean() > idx_train.mean()*(y_train==1).mean()\n",
    "        baserate_train = y_train[idx_train].mean()*100\n",
    "        # delta = (pred[idx]==1).mean() - (y_test[idx]==1).mean()\n",
    "        # ind = np.logical_and(idx, y_test==1).mean() > idx.mean()*(y_test==1).mean()\n",
    "        ba = (ind*delta + (~ind)*(-delta)) * 100\n",
    "    \n",
    "        print()\n",
    "        print(g1, g2)\n",
    "        print('- Count', count)\n",
    "        print('- TP {}, FP {}, TN {}, FN {}'.format(tp, fp, tn, fn))\n",
    "        print('- Accuracy {:.2f}'.format(accuracy))\n",
    "        print('- PPV {:.2f}'.format(ppv))\n",
    "        print('- TPR {:.2f}'.format(tpr))\n",
    "        print('- FPR {:.2f}'.format(fpr))\n",
    "        print('- FNR {:.2f}'.format(fnr))\n",
    "        print('- GT positive outcome (train) {:.2f}'.format(baserate_train))\n",
    "        print('- GT positive outcome (test) {:.2f}'.format(baserate))\n",
    "        print('- Predicted positive outcome (test) {:.2f}'.format(po))\n",
    "        # print('- Delta {:.2f}'.format(delta))\n",
    "        # print('- Indicator {}'.format(ind))\n",
    "        print('- Bias amplification {:.2f}'.format(ba))\n",
    "\n",
    "# print('\\nTotal {}, Missing {}'.format(pred.shape[0], pred.shape[0]-empty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
