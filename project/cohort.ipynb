{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import params as pm\n",
    "import datetime as dt\n",
    "import json\n",
    "import pickle\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-bacon",
   "metadata": {},
   "source": [
    "# Select cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_cohort(adults=True, patient_weight=True, icd_diagnoses=[], min_los=1, max_los=8, verbose=False):\n",
    "    cohort = pd.read_csv(\"data/mimic-iv-1.0/icu/icustays.csv\")\n",
    "    # Filter for adults with icustay length between 1 and 8 days\n",
    "    cohort = cohort[cohort['los'] >= min_los]\n",
    "    cohort = cohort[cohort['los'] <= max_los]\n",
    "    cohort = cohort[['subject_id', 'stay_id', 'hadm_id', 'intime', 'outtime', 'los']]\n",
    "\n",
    "    ages = pd.read_csv(\"data/mimic-iv-1.0/core/patients.csv\")\n",
    "    ages = ages[ages['anchor_age'] >= 18]\n",
    "    ages = ages[['subject_id', 'gender', 'anchor_age', 'anchor_year', 'anchor_year_group']]\n",
    "\n",
    "    admissions = pd.merge(cohort, ages, on=['subject_id'])\n",
    "\n",
    "    # Admissions + Age information\n",
    "    admissions = pd.merge(admissions, ages, on=['subject_id', 'gender', 'anchor_age'], how='inner')\n",
    "    admissions\n",
    "    if patient_weight:\n",
    "        if verbose: print(\"Adding information about patientweight\")\n",
    "        # Add patient weight information\n",
    "        weights = pd.read_csv(\"data/mimic-iv-1.0/icu/procedureevents.csv\")\n",
    "        weights = weights[['stay_id', 'hadm_id', 'patientweight']]\n",
    "        admissions = pd.merge(admissions, weights, on=['hadm_id', 'stay_id']).drop_duplicates()\n",
    "    admissions\n",
    "    \n",
    "    if len(icd_diagnoses) > 0:\n",
    "        if verbose: print(\"Filtering for ICD diagnoses\")\n",
    "        diagnoses_icd = pd.read_csv(\"data/mimic-iv-1.0/hosp/diagnoses_icd.csv\")\n",
    "        diagnoses_icd = diagnoses_icd[diagnoses_icd[['icd_code', 'icd_version']].apply(tuple, axis=1).isin(icd_diagnoses)]\n",
    "        diagnoses = diagnoses_icd[['hadm_id', 'icd_code', 'icd_version']]\n",
    "        admissions = pd.merge(admissions, diagnoses, on=['hadm_id']).drop_duplicates()\n",
    "\n",
    "    hadm_ids = admissions.hadm_id.unique()\n",
    "\n",
    "    return hadm_ids, admissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-rwanda",
   "metadata": {},
   "source": [
    "# Gather dataframes with basic vitals + meds + labs for each cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-understanding",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Gathers all ICU level medications. \n",
    "'''\n",
    "def gather_meds(meds_dict, verbose=False):\n",
    "    meds_ids = []\n",
    "    for key in meds_dict:\n",
    "        names = meds_dict[key]\n",
    "        meds_ids += names\n",
    "\n",
    "    if verbose: print(\"Gathering meds\")    \n",
    "    meds = pd.read_csv(\"data/mimic-iv-1.0/icu/inputevents.csv\")\n",
    "    meds = meds[meds['itemid'].isin(meds_ids)]\n",
    "    meds = meds[meds['amount'] > 0]\n",
    "    meds = meds[meds['amount'] < 9999]\n",
    "    \n",
    "    if verbose: print(\"Saving dataframes\")\n",
    "    meds = meds.drop_duplicates()\n",
    "    meds.to_pickle('meds')\n",
    "    return meds\n",
    "\n",
    "'''\n",
    "Gather all vitals records. \n",
    "'''\n",
    "def gather_vitals(vitals_dict, verbose=False):\n",
    "    vitals_itemids = []\n",
    "    for key in vitals_dict:\n",
    "        itemid = vitals_dict[key]\n",
    "        vitals_itemids.extend(itemid)\n",
    "    if verbose: print(\"Gathering vitals\")\n",
    "    vitals = pd.read_csv(\"data/mimic-iv-1.0/icu/chartevents.csv\")\n",
    "    vitals = vitals[vitals['itemid'].isin(vitals_itemids)]\n",
    "    vitals = vitals[vitals['valuenum'] >= 0]\n",
    "    vitals = vitals[vitals['valuenum'] < 9999]\n",
    "    \n",
    "    if verbose: print(\"Saving dfs\")\n",
    "    filtered_vitals_df = vitals.drop_duplicates()\n",
    "    filtered_vitals_df.to_pickle('vitals')\n",
    "\n",
    "    return filtered_vitals_df\n",
    "\n",
    "'''\n",
    "Gather urine output. \n",
    "'''\n",
    "def gather_outputs(output_itemids, verbose=False):\n",
    "\n",
    "    if verbose: print(\"Gathering outputs\")\n",
    "    outputs = pd.read_csv(\"data/mimic-iv-1.0/icu/outputevents.csv\")\n",
    "    ouptuts = outputs[outputs['itemid'].isin(output_itemids)]\n",
    "    outputs = outputs[outputs['value'] >= 0]\n",
    "    outputs = outputs[outputs['value'] < 99999]\n",
    "\n",
    "    filtered_output_df = outputs\n",
    "\n",
    "    if verbose: print(\"Saving dataframes\")\n",
    "    filtered_output_df.to_pickle('output')\n",
    "    return filtered_output_df\n",
    "\n",
    "'''\n",
    "Gathers information about ICU level labs. \n",
    "'''\n",
    "def gather_labs(labs_dict, verbose=False):\n",
    "    labs_itemids = []\n",
    "    for key in labs_dict:\n",
    "        itemids = labs_dict[key]\n",
    "        labs_itemids += itemids\n",
    "\n",
    "    if verbose: print(\"Gathering labs\")\n",
    "    labs = pd.read_csv(\"data/mimic-iv-1.0/icu/chartevents.csv\")\n",
    "    labs = labs[labs['itemid'].isin(labs_itemids)]\n",
    "    labs = labs[labs['valuenum'] >= 0]\n",
    "    labs = labs[labs['valuenum'] < 99999]\n",
    "    \n",
    "    filtered_labs_df = labs.drop_duplicates()\n",
    "\n",
    "    if verbose: print(\"Saving dataframes\")\n",
    "    filtered_labs_df.to_pickle('labs')\n",
    "    return filtered_labs_df\n",
    "'''\n",
    "Gather ventilator procedures. \n",
    "'''\n",
    "def gather_vent(vent_dict, verbose=False):\n",
    "    vent_ids = []\n",
    "    for key in vent_dict:\n",
    "        vent_ids += vent_dict[key]\n",
    "    \n",
    "    if verbose: print(\"Gathering ventilator info\")\n",
    "    inputevents = pd.read_csv(\"data/mimic-iv-1.0/icu/inputevents.csv\")\n",
    "    vent = inputevents[inputevents['itemid'].isin(vent_ids)]\n",
    "    vent = vent[vent['amount'] > 0]\n",
    "    vent = vent[vent['amount'] < 99999]\n",
    "    \n",
    "    vent = vent.drop_duplicates()\n",
    "    if verbose: print(\"Saving dataframes\")\n",
    "    vent.to_pickle('vent')\n",
    "    return vent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-programming",
   "metadata": {},
   "source": [
    "# ChartFrames for both cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-dover",
   "metadata": {
    "code_folding": [
     34,
     40,
     50,
     69,
     93,
     141
    ]
   },
   "outputs": [],
   "source": [
    "def buildTimeFrame(df_adm, delta=6):\n",
    "\n",
    "    # Get admit and discharge time in numeric form, round down/up respectively to the nearest hour:\n",
    "    start = pd.to_datetime(df_adm.intime.unique()).tolist()[0]\n",
    "    start -= dt.timedelta(minutes=start.minute, seconds=start.second, microseconds=start.microsecond)\n",
    "\n",
    "    end = pd.to_datetime(df_adm.outtime.unique()).tolist()[0]\n",
    "    end -= dt.timedelta(minutes=end.minute, seconds=end.second, microseconds=end.microsecond)\n",
    "    end += dt.timedelta(hours=1)\n",
    "\n",
    "    times = []\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        times.append(curr)\n",
    "        curr += dt.timedelta(hours=delta)\n",
    "    timeFrame = pd.DataFrame(data={'timestamp': times}, index=times)\n",
    "    return timeFrame\n",
    "\n",
    "'''\n",
    "Build time-indexed dataframe of each patient admission, with resampled values of all variables.\n",
    "hadm_id: hadm_id of the patient stay\n",
    "tables: all of the tables generated in _load_data() \n",
    "popmeans: population level means used for imputation\n",
    "verbose: flag for printing progress\n",
    "timedelta: length in hours of the time interval for the rows\n",
    "'''\n",
    "def chartFrames(hadm_id, tables, verbose=False, timedelta=6):\n",
    "\n",
    "    adm = 1; morb = 1; vits = 1; lbs = 1; mds = 1; prcs = 0; vnt = 1\n",
    "    admissions, meds, vitals, labs, outputs, vent = tables\n",
    "\n",
    "    df_adm = admissions[admissions.hadm_id == hadm_id].drop_duplicates()\n",
    "    chart = buildTimeFrame(df_adm)\n",
    "\n",
    "    if adm:\n",
    "        if verbose: print('Admission Data')\n",
    "        for var in ['stay_id', 'anchor_age', 'patientweight', 'los', 'gender']:\n",
    "            chart[var.lower()] = df_adm[var].head(1).item()\n",
    "        chart['gender'] = (chart['gender'] == 'F').astype(int)\n",
    "\n",
    "    if morb:\n",
    "        if verbose: print(\"Comorbidities\")\n",
    "        df_comorbs = comorbs[comorbs.hadm_id == hadm_id]\n",
    "        for subpop in self.params.comorbidities_dict:\n",
    "            subpop_df = df_comorbs[df_comorbs.long_title.isin(self.params.comorbidities_dict[subpop])]\n",
    "            if subpop_df.empty:\n",
    "                chart[subpop] = 0\n",
    "            else:\n",
    "                chart[subpop] = 1\n",
    "        chart['expired'] = 0\n",
    "    if lbs:\n",
    "        if verbose: print('Lab tests')  # Using result date\n",
    "        df_labs = labs[labs.hadm_id == hadm_id].drop_duplicates()\n",
    "\n",
    "        # ICU Labs\n",
    "        for k in sorted(list(pm.labs_dict_icu.keys())):\n",
    "            chart[k.lower()] = np.nan\n",
    "            for t in chart.timestamp:\n",
    "                subset = df_labs[df_labs['itemid'].isin(pm.labs_dict_icu[k])]\n",
    "                for i in subset.index:\n",
    "                    if ((pd.to_datetime(subset.loc[i, 'charttime']) >= t) & (\n",
    "                        pd.to_datetime(subset.loc[i, 'charttime']) < t + dt.timedelta(hours=timedelta))):\n",
    "                        if k not in ['Ca', 'Glucose', 'CPK', 'PTH', 'LDH', 'AST', 'ALT']:\n",
    "                            chart.loc[t, k.lower()] = np.nanmean([chart.loc[t, k.lower()], subset.loc[i, 'valuenum']])\n",
    "                        else:\n",
    "                            chart.loc[t, k.lower()] = 1\n",
    "\n",
    "            chart[k.lower()] = chart[k.lower()].fillna(method='ffill', limit=3).fillna(value=0)\n",
    "\n",
    "    if vits:\n",
    "        if verbose: print('Vitals')\n",
    "        df_vits = vitals[vitals.hadm_id == hadm_id]\n",
    "        for k in sorted(list(pm.vitals_dict_icu.keys())):\n",
    "            if k == \"URINE_OUTPUT\":\n",
    "                continue\n",
    "            chart[k.lower()] = np.nan\n",
    "            for t in chart.timestamp:\n",
    "                subset = df_vits[df_vits.itemid.isin(pm.vitals_dict_icu[k])]\n",
    "                for i in subset.index:\n",
    "                    try:\n",
    "                        if ((pd.to_datetime(subset.loc[i, 'charttime']) >= t) & (\n",
    "                            pd.to_datetime(subset.loc[i, 'charttime']) < t + dt.timedelta(hours=timedelta))):\n",
    "                            chart.loc[t, k.lower()] = np.nanmean([chart.loc[t, k.lower()], subset.loc[i, 'value']])\n",
    "                    except:\n",
    "                        try:\n",
    "                            if ((pd.to_datetime(subset.loc[i, 'charttime']) >= t).any() & (\n",
    "                                pd.to_datetime(subset.loc[i, 'charttime']) < t + dt.timedelta(hours=timedelta)).any()):\n",
    "                                chart.loc[t, k.lower()] = np.nanmean([chart.loc[t, k.lower()], subset.loc[i, 'value']])\n",
    "                        except:\n",
    "                            pass\n",
    "            chart[k.lower()] = chart[k.lower()].fillna(method='ffill').fillna(value=0)\n",
    "\n",
    "\n",
    "    if mds:\n",
    "        if verbose: print('Medications')\n",
    "        df_meds = meds[meds.hadm_id==hadm_id].drop_duplicates()\n",
    "        for k in sorted(list(pm.meds_dict_icu.keys())):\n",
    "            chart[k.lower()] = 0\n",
    "            subset = df_meds[df_meds.itemid.isin(pm.meds_dict_icu[k])]\n",
    "            for t in chart.timestamp:\n",
    "                for i, row in subset.iterrows():\n",
    "                    if row.amountuom == 'dose':\n",
    "                        continue\n",
    "                    if ((pd.to_datetime(row.starttime) >= t) and (pd.to_datetime(row.starttime) <  t + dt.timedelta(hours=timedelta))):\n",
    "                        if k in ['K-IV', 'K-nonIV', 'Mg-IV', 'Mg-nonIV', 'P-IV', 'P-nonIV']:\n",
    "                            scaler = 1\n",
    "                            if row.amountuom == 'grams':\n",
    "                                scaler = 1000\n",
    "                            elif row.amountuom == 'mcg':\n",
    "                                scaler = 0.001\n",
    "                            elif row.amountuom == 'pg':\n",
    "                                scaler = 1e-9\n",
    "                            elif row.amountuom == 'ml':\n",
    "                                scaler = 1\n",
    "                            chart.loc[t, k.lower()] += scaler * float(row.amount)\n",
    "                            td = pd.to_datetime(row.endtime) - pd.to_datetime(row.starttime)\n",
    "                            hours = td.days * 24 + td.seconds // 3600\n",
    "                            chart.loc[t, 'hours-'+k.lower()] = hours\n",
    "                        else:\n",
    "                            chart.loc[t, k.lower()] += 1\n",
    "                    if row.endtime is not np.nan:\n",
    "                        if ((pd.to_datetime(row.starttime) <= t) and (pd.to_datetime(row.endtime) > t)):\n",
    "                            if k in ['K-IV', 'K-nonIV', 'Mg-IV', 'Mg-nonIV', 'P-IV', 'P-nonIV']:\n",
    "                                scaler = 1\n",
    "                                if row.amountuom == 'grams':\n",
    "                                    scaler = 1000\n",
    "                                elif row.amountuom == 'mcg':\n",
    "                                    scaler = 0.001\n",
    "                                elif row.amountuom == 'pg':\n",
    "                                    scaler = 1e-9\n",
    "                                elif row.amountuom == 'ml':\n",
    "                                    scaler = 1\n",
    "                                chart.loc[t, k.lower()] += scaler * float(row.amount)\n",
    "                                td = pd.to_datetime(row.endtime) - pd.to_datetime(row.starttime)\n",
    "                                hours = td.days * 24 + td.seconds // 3600\n",
    "                                chart.loc[t, 'hours-'+k.lower()] = hours\n",
    "                            else:\n",
    "                                chart.loc[t, k.lower()] += 1\n",
    "    if vnt:\n",
    "        if verbose: print('Ventilation')\n",
    "        df_vent = vent[vent.hadm_id == hadm_id].drop_duplicates()\n",
    "        if df_vent.empty:\n",
    "            chart['vent'] = 0\n",
    "        else:\n",
    "            chart['vent'] = np.nan\n",
    "            for t in chart.timestamp:\n",
    "                for i in df_adm.index:\n",
    "                    if ((pd.to_datetime(df_vent.loc[i, 'charttime']) >= t) and (\n",
    "                        pd.to_datetime(df_vent.loc[i, 'charttime']) < t + dt.timedelta(hours=6))):\n",
    "                        chart.loc[t, 'vent'] = np.nanmean([chart.loc[t, 'vent'], df_vent.loc[i, 'value']])\n",
    "                    else:\n",
    "                        chart.loc[t, 'vent'] = 0\n",
    "\n",
    "    chart = chart[~np.isnat(chart.timestamp)]\n",
    "    chart = chart.dropna()\n",
    "    if verbose: print('Done!')\n",
    "\n",
    "    return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridBatch(patient_ids, tables, name):\n",
    "    batchCharts = pd.DataFrame()\n",
    "\n",
    "    for i, vnum in tqdm.tqdm(enumerate(patient_ids)):\n",
    "        #try:\n",
    "        chart = chartFrames(vnum, tables, verbose=False)\n",
    "        batchCharts = batchCharts.append(chart, ignore_index=True)\n",
    "        if i % 50 == 0:\n",
    "            batchCharts.to_csv(str(i) + '_' + str(name) + '_checkpoint.csv', index=False)\n",
    "        #except:\n",
    "        #    print(\"Issue in : \" + str(vnum))\n",
    "    print('Batch done!')\n",
    "    batchCharts.to_csv(name + '_allFrames.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographic_info(hadm_ids):    \n",
    "    admissions = pd.read_csv(\"data/mimic-iv-1.0/core/admissions.csv\")\n",
    "    admissions = admissions[admissions['hadm_id'].isin(hadm_ids)]\n",
    "    admissions = admissions[['hadm_id', 'insurance', 'marital_status', 'ethnicity']]\n",
    "        \n",
    "    return admissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-heart",
   "metadata": {},
   "source": [
    "# Generate tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if this is the first time\n",
    "meds = gather_meds(pm.meds_dict_icu, verbose=True)\n",
    "vitals = gather_vitals(pm.vitals_dict_icu, verbose=True)\n",
    "outputs = gather_outputs(pm.vitals_dict_icu['Urine'], verbose=True)\n",
    "labs = gather_labs(pm.labs_dict_icu, verbose=True)\n",
    "vent = gather_vent(pm.vent_dict, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you have saved dataframes\n",
    "meds = pickle.load(open('meds', 'rb'))\n",
    "vitals = pickle.load(open('vitals', 'rb'))\n",
    "outputs = pickle.load(open('outputs', 'rb'))\n",
    "labs = pickle.load(open('labs', 'rb'))\n",
    "vent = pickle.load(open('vent', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-trigger",
   "metadata": {},
   "source": [
    "## Melanoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_icd = pd.read_csv(\"data/mimic-iv-1.0/hosp/d_icd_diagnoses.csv\")\n",
    "melanoma_codes = diagnoses_icd[diagnoses_icd['long_title'].str.contains('melanoma')]\n",
    "melanoma = []\n",
    "for c, v in zip(melanoma_codes['icd_code'], melanoma_codes['icd_version']):\n",
    "    melanoma.append((c, v))\n",
    "hadm_ids, admissions = gather_cohort(icd_diagnoses=melanoma, verbose=True)\n",
    "demographics = demographic_info(hadm_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridBatch(hadm_ids, (admissions, meds, vitals, labs, outputs, vent), 'melanoma')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-instruction",
   "metadata": {},
   "source": [
    "## Heart Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_names = ['Atherosclerotic heart disease of native coronary artery without angina pectoris',\n",
    "'Atherosclerotic heart disease of native coronary artery with unstable angina pectoris', \n",
    "'Atherosclerotic heart disease of native coronary artery with angina pectoris with documented spasm', \n",
    "'Atherosclerotic heart disease of native coronary artery with other forms of angina pectoris', \n",
    "'Atherosclerotic heart disease of native coronary artery with unspecified angina pectoris']\n",
    "diagnoses_icd = pd.read_csv(\"data/mimic-iv-1.0/hosp/d_icd_diagnoses.csv\")\n",
    "hd_codes = diagnoses_icd[diagnoses_icd['long_title'].isin(cad_names)]\n",
    "hd = []\n",
    "for c, v in zip(hd_codes['icd_code'], hd_codes['icd_version']):\n",
    "    hd.append((c, v))\n",
    "hadm_ids, admissions = gather_cohort(icd_diagnoses=hd, verbose=True)\n",
    "demographics = demographic_info(hadm_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridBatch(hadm_ids, (admissions, meds, vitals, labs, outputs, vent), 'hd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-complexity",
   "metadata": {},
   "source": [
    "## Flu/Pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_names = []\n",
    "diagnoses_icd = pd.read_csv(\"data/mimic-iv-1.0/hosp/d_icd_diagnoses.csv\")\n",
    "all_diag = diagnoses_icd['long_title']\n",
    "for d in all_diag:\n",
    "    if \"pneumonia\" in d.lower():\n",
    "        fp_names.append(d)\n",
    "    if \"influenz\" in d.lower():\n",
    "        fp_names.append(d)\n",
    "fp_names = list(set(fp_names))\n",
    "hd_codes = diagnoses_icd[diagnoses_icd['long_title'].isin(fp_names)]\n",
    "hd = []\n",
    "for c, v in zip(hd_codes['icd_code'], hd_codes['icd_version']):\n",
    "    hd.append((c, v))\n",
    "hadm_ids, admissions = gather_cohort(icd_diagnoses=hd, verbose=True)\n",
    "demographics = demographic_info(hadm_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridBatch(hadm_ids, (admissions, meds, vitals, labs, outputs, vent), 'hd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-bandwidth",
   "metadata": {},
   "source": [
    "## Kidney Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_icd = pd.read_csv(\"data/mimic-iv-1.0/hosp/d_icd_diagnoses.csv\")\n",
    "diag_codes = diagnoses_icd[diagnoses_icd['long_title'].str.contains('end stage renal disease')]\n",
    "rd_codes = diag_codes\n",
    "hd = []\n",
    "for c, v in zip(rd_codes['icd_code'], rd_codes['icd_version']):\n",
    "    hd.append((c, v))\n",
    "procedures_desc = pd.read_csv('data/mimic-iv-1.0/hosp/d_icd_procedures.csv')\n",
    "procedures_df = pd.read_csv('data/mimic-iv-1.0/hosp/procedures_icd.csv')\n",
    "procedures_desc['long_title'] = procedures_desc['long_title'].str.lower()\n",
    "# last 19 items are related to imaging procedures so ignore them\n",
    "transplant_procedure_codes = procedures_desc[procedures_desc['long_title'].str.contains('transplant')]\n",
    "for c, v in zip(transplant_procedure_codes['icd_code'], transplant_procedure_codes['icd_version']):\n",
    "    hd.append((c, v))\n",
    "\n",
    "hadm_ids, admissions = gather_cohort(icd_diagnoses=hd, verbose=True)\n",
    "demographics = demographic_info(hadm_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-stand",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
