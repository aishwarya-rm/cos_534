{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>patientweight</th>\n",
       "      <th>los</th>\n",
       "      <th>gender</th>\n",
       "      <th>alb</th>\n",
       "      <th>aniongap</th>\n",
       "      <th>bun</th>\n",
       "      <th>...</th>\n",
       "      <th>pnutrition</th>\n",
       "      <th>ponutrition</th>\n",
       "      <th>packedrbc</th>\n",
       "      <th>paralytics</th>\n",
       "      <th>sedation</th>\n",
       "      <th>tpnutrition</th>\n",
       "      <th>vasoactive</th>\n",
       "      <th>vasopressors</th>\n",
       "      <th>hours-p-iv</th>\n",
       "      <th>deceased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2160-10-17 19:00:00</td>\n",
       "      <td>30062923</td>\n",
       "      <td>79</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1.027708</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2124-04-08 03:00:00</td>\n",
       "      <td>30065290</td>\n",
       "      <td>75</td>\n",
       "      <td>69.6</td>\n",
       "      <td>2.841146</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2122-04-22 04:00:00</td>\n",
       "      <td>30066446</td>\n",
       "      <td>83</td>\n",
       "      <td>82.2</td>\n",
       "      <td>6.355139</td>\n",
       "      <td>1</td>\n",
       "      <td>2.65</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2158-06-30 18:00:00</td>\n",
       "      <td>30139247</td>\n",
       "      <td>83</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.832755</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2158-07-01 00:00:00</td>\n",
       "      <td>30139247</td>\n",
       "      <td>83</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.832755</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            timestamp   stay_id  anchor_age  patientweight  \\\n",
       "0           0  2160-10-17 19:00:00  30062923          79          147.0   \n",
       "1           1  2124-04-08 03:00:00  30065290          75           69.6   \n",
       "2           2  2122-04-22 04:00:00  30066446          83           82.2   \n",
       "3           3  2158-06-30 18:00:00  30139247          83           75.0   \n",
       "4           4  2158-07-01 00:00:00  30139247          83           75.0   \n",
       "\n",
       "        los  gender   alb  aniongap   bun  ...  pnutrition  ponutrition  \\\n",
       "0  1.027708       0  0.00      14.0  14.0  ...           0            0   \n",
       "1  2.841146       1  0.00      10.0  21.0  ...           0            0   \n",
       "2  6.355139       1  2.65      17.0   7.0  ...           0            0   \n",
       "3  2.832755       0  0.00      15.0  32.0  ...           0            0   \n",
       "4  2.832755       0  0.00      15.0  32.0  ...           0            0   \n",
       "\n",
       "   packedrbc  paralytics  sedation  tpnutrition  vasoactive  vasopressors  \\\n",
       "0          0           0         4            0           0             0   \n",
       "1          0           0         1            0           0             0   \n",
       "2          0           0         0            0           0             0   \n",
       "3          0           0         0            0           0             0   \n",
       "4          0           0         0            0           0             0   \n",
       "\n",
       "   hours-p-iv  deceased  \n",
       "0         NaN         0  \n",
       "1         NaN         0  \n",
       "2         NaN         0  \n",
       "3         NaN         0  \n",
       "4         NaN         0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melanoma_df = pd.read_csv('melanoma_allFrames_w_death.csv')\n",
    "melanoma_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with LSTM layers\n",
    "\n",
    "We will treat this as a text classification problem, where each vital is a word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TRAIN_COLS = ['anchor_age', 'patientweight', 'los', 'gender',\n",
    "       'alb', 'aniongap', 'bun', 'crp', 'ca', 'chloride', 'creatinine',\n",
    "       'fibrinogen', 'glucose', 'hgb', 'k', 'mg', 'na', 'p', 'platelets',\n",
    "       'troponin', 'wbc', 'apneainterval', 'artco2p', 'arto2p', 'expratio',\n",
    "       'hr', 'inspratio', 'insptime', 'nibpd', 'nibpm', 'nibps', 'pip', 'rr',\n",
    "       'spo2', 'temp', 'urine', 'vm', 'vt', 'betablockers', 'ca-iv',\n",
    "       'ca-noniv', 'cablockers', 'dextrose', 'fluids', 'insulin', 'k-iv',\n",
    "       'hours-k-iv', 'loopdiuretics', 'mg-iv', 'mg-noniv', 'hours-mg-noniv',\n",
    "       'p-iv', 'p-noniv', 'pnutrition', 'ponutrition', 'packedrbc',\n",
    "       'paralytics', 'sedation', 'tpnutrition', 'vasoactive', 'vasopressors',\n",
    "       'hours-p-iv']\n",
    "\n",
    "pred_var = 'deceased'\n",
    "\n",
    "X = melanoma_df[TRAIN_COLS]\n",
    "X = X.fillna(-1)\n",
    "y = melanoma_df[pred_var]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "x_t, X_val, y_t, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(len(x_t.columns), activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                  optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "model = get_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_103 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 14.7799 - accuracy: 0.0234WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30 batches). You may need to use the repeat() function when building your dataset.\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 14.1974 - accuracy: 0.0634 - val_loss: 14.5126 - val_accuracy: 0.0483\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 13.1207 - accuracy: 0.1321\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 11.1859 - accuracy: 0.2530\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 7.1717 - accuracy: 0.5161\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 4.4535 - accuracy: 0.6971\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.7808 - accuracy: 0.8110\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.8468 - accuracy: 0.8765\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3515 - accuracy: 0.9108\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1388 - accuracy: 0.9248\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0811 - accuracy: 0.9275\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0161 - accuracy: 0.9318\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0980 - accuracy: 0.9270\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0393 - accuracy: 0.9313\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0308 - accuracy: 0.9323\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8883 - accuracy: 0.9404\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8033 - accuracy: 0.9468\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.9570\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7680 - accuracy: 0.9501\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7297 - accuracy: 0.9517\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6705 - accuracy: 0.9560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15f101208>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_t, y_t))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "model.fit(train_dataset, \n",
    "          epochs=20,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "TRAIN_COLS = ['anchor_age', 'patientweight', 'gender',\n",
    "       'alb', 'aniongap', 'bun', 'crp', 'ca', 'chloride', 'creatinine',\n",
    "       'fibrinogen', 'glucose', 'hgb', 'k', 'mg', 'na', 'p', 'platelets',\n",
    "       'troponin', 'wbc', 'apneainterval', 'artco2p', 'arto2p', 'expratio',\n",
    "       'hr', 'inspratio', 'insptime', 'nibpd', 'nibpm', 'nibps', 'pip', 'rr',\n",
    "       'spo2', 'temp', 'urine', 'vm', 'vt', 'betablockers', 'ca-iv',\n",
    "       'ca-noniv', 'cablockers', 'dextrose', 'fluids', 'insulin', 'k-iv',\n",
    "       'hours-k-iv', 'loopdiuretics', 'mg-iv', 'mg-noniv', 'hours-mg-noniv',\n",
    "       'p-iv', 'p-noniv', 'pnutrition', 'ponutrition', 'packedrbc',\n",
    "       'paralytics', 'sedation', 'tpnutrition', 'vasoactive', 'vasopressors',\n",
    "       'hours-p-iv',  'deceased']\n",
    "\n",
    "pred_var = 'los'\n",
    "\n",
    "X = melanoma_df[TRAIN_COLS]\n",
    "X = X.fillna(-1)\n",
    "y = melanoma_df[pred_var]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "x_t, X_val, y_t, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(len(x_t.columns), activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
    "                  loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "model = get_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.6025 - accuracy: 0.9609WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30 batches). You may need to use the repeat() function when building your dataset.\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.9565 - val_loss: 0.6706 - val_accuracy: 0.9565\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.9570\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.9560\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6219 - accuracy: 0.9586\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.9613\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.9565\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.9576\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.9570\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.9581\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.9608\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.9603\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.9613\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.9613\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.9570\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.9619\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.9592\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.9592\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.9619\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.9597\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.9619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15f0fe9e8>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_t, y_t))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "model.fit(train_dataset, \n",
    "          epochs=20,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
