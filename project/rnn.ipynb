{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>patientweight</th>\n",
       "      <th>los</th>\n",
       "      <th>gender</th>\n",
       "      <th>alb</th>\n",
       "      <th>aniongap</th>\n",
       "      <th>bun</th>\n",
       "      <th>crp</th>\n",
       "      <th>...</th>\n",
       "      <th>paralytics</th>\n",
       "      <th>sedation</th>\n",
       "      <th>tpnutrition</th>\n",
       "      <th>vasoactive</th>\n",
       "      <th>vasopressors</th>\n",
       "      <th>vent</th>\n",
       "      <th>hours-k-iv</th>\n",
       "      <th>hours-mg-noniv</th>\n",
       "      <th>hours-p-iv</th>\n",
       "      <th>hours-mg-iv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2144-02-22 21:00:00</td>\n",
       "      <td>31055329</td>\n",
       "      <td>48</td>\n",
       "      <td>74.4</td>\n",
       "      <td>2.774931</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>249.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2144-02-23 03:00:00</td>\n",
       "      <td>31055329</td>\n",
       "      <td>48</td>\n",
       "      <td>74.4</td>\n",
       "      <td>2.774931</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>249.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2144-02-23 09:00:00</td>\n",
       "      <td>31055329</td>\n",
       "      <td>48</td>\n",
       "      <td>74.4</td>\n",
       "      <td>2.774931</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>258.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2144-02-23 15:00:00</td>\n",
       "      <td>31055329</td>\n",
       "      <td>48</td>\n",
       "      <td>74.4</td>\n",
       "      <td>2.774931</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>258.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2144-02-23 21:00:00</td>\n",
       "      <td>31055329</td>\n",
       "      <td>48</td>\n",
       "      <td>74.4</td>\n",
       "      <td>2.774931</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>258.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp   stay_id  anchor_age  patientweight       los  gender  \\\n",
       "0  2144-02-22 21:00:00  31055329          48           74.4  2.774931       0   \n",
       "1  2144-02-23 03:00:00  31055329          48           74.4  2.774931       0   \n",
       "2  2144-02-23 09:00:00  31055329          48           74.4  2.774931       0   \n",
       "3  2144-02-23 15:00:00  31055329          48           74.4  2.774931       0   \n",
       "4  2144-02-23 21:00:00  31055329          48           74.4  2.774931       0   \n",
       "\n",
       "   alb  aniongap    bun    crp  ...  paralytics  sedation  tpnutrition  \\\n",
       "0  0.0      21.0  130.0  249.7  ...           0         2            0   \n",
       "1  0.0      21.0  130.0  249.7  ...           0         1            0   \n",
       "2  0.0      23.0  130.0  258.2  ...           0         1            0   \n",
       "3  0.0      23.0  130.0  258.2  ...           0         1            0   \n",
       "4  0.0      23.0  132.0  258.2  ...           0         0            0   \n",
       "\n",
       "   vasoactive  vasopressors  vent  hours-k-iv  hours-mg-noniv  hours-p-iv  \\\n",
       "0           0             0     0         NaN             NaN         NaN   \n",
       "1           0             0     0         NaN             NaN         NaN   \n",
       "2           0             0     0         NaN             NaN         NaN   \n",
       "3           0             0     0         NaN             NaN         NaN   \n",
       "4           0             0     0         NaN             NaN         NaN   \n",
       "\n",
       "   hours-mg-iv  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_df = pd.read_csv('kidney_allFrames.csv')\n",
    "kidney_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = pd.read_csv(\"data/mimic-iv-1.0/icu/icustays.csv.gz\", compression='gzip')\n",
    "diagnoses_icd = pd.read_csv(\"data/mimic-iv-1.0/hosp/diagnoses_icd.csv.gz\", compression='gzip')\n",
    "\n",
    "TRANSPLANT_CODES = ['0091', '0092', '0093', '02Y', '02YA0Z0', '02YA0Z1', \n",
    "                    '02YA0Z2', '0794', '07Y', '07YM0Z0', '07YM0Z1', '07YM0Z2', \n",
    "                    '07YP0Z0', '07YP0Z1', '07YP0Z2', '0BYM0Z0', '0BYM0Z1', \n",
    "                    '0BY', '0BYC0Z0', '0BYC0Z1', '0BYC0Z2', '0BYD0Z0', '0BYD0Z1', \n",
    "                    '0BYD0Z2', '0BYF0Z0', '0BYF0Z1', '0BYF0Z2', '0BYG0Z0', '0BYG0Z1', \n",
    "                    '0BYG0Z2', '0BYH0Z0', '0BYH0Z1', '0BYH0Z2', '0BYJ0Z0', '0BYJ0Z1',\n",
    "                    '0BYJ0Z2', '0BYK0Z0', '0BYK0Z1', '0BYK0Z2', '0BYL0Z0', '0BYL0Z1', \n",
    "                    '0BYL0Z2', '0BYM0Z2', '0DY', '0DY50Z0', '0DY50Z1', '0DY50Z2', \n",
    "                    '0DY60Z0', '0DY60Z1', '0DY60Z2', '0DY80Z0', '0DY80Z1', '0DY80Z2',\n",
    "                    '0DYE0Z0', '0DYE0Z1', '0DYE0Z2', '0FY', '0FY00Z0', '0FY00Z1', \n",
    "                    '0FY00Z2', '0FYG0Z0', '0FYG0Z1', '0FYG0Z2', '0TY', '0TY00Z0',\n",
    "                    '0TY00Z1', '0TY00Z2', '0TY10Z0', '0TY10Z1', '0TY10Z2', '0UY',\n",
    "                    '0UY00Z0', '0UY00Z1', '0UY00Z2', '0UY10Z0', '0UY10Z1', '0UY10Z2', \n",
    "                    '0UY90Z0', '0UY90Z1', '0UY90Z2', '0WY', '0WY20Z0', '0WY20Z1', '0XY', \n",
    "                    '0XYJ0Z0', '0XYJ0Z1', '0XYK0Z0', '0XYK0Z1', '10Y', '10Y03ZE', \n",
    "                    '10Y03ZF', '10Y03ZG', '10Y03ZH', '10Y03ZJ', '10Y03ZK', '10Y03ZL', \n",
    "                    '10Y03ZM', '10Y03ZN', '10Y03ZP', '10Y03ZQ', '10Y03ZR', '10Y03ZS', \n",
    "                    '10Y03ZT', '10Y03ZV', '10Y03ZY', '10Y04ZE', '10Y04ZF', '10Y04ZG', \n",
    "                    '10Y04ZH', '10Y04ZJ', '10Y04ZK', '10Y04ZL', '10Y04ZM', '10Y04ZN', \n",
    "                    '10Y04ZP', '10Y04ZQ', '10Y04ZR', '10Y04ZS', '10Y04ZT', '10Y04ZV', \n",
    "                    '10Y04ZY', '10Y07ZE', '10Y07ZF', '10Y07ZG', '10Y07ZH', '10Y07ZJ', \n",
    "                    '10Y07ZK', '10Y07ZL', '10Y07ZM', '10Y07ZN', '10Y07ZP', '10Y07ZQ', \n",
    "                    '10Y07ZR', '10Y07ZS', '10Y07ZT', '10Y07ZV', '10Y07ZY', '1160', \n",
    "                    '1169', '3350', '3351', '3352', '336', '3751', '4100', '4101', \n",
    "                    '4102', '4103', '4104', '4106', '4107', '4108', '4109', '4191', \n",
    "                    '4194', '4697', '4974', '5051', '5059', '5280', '5282', '5283', \n",
    "                    '5284', '5285', '5286', '5553', '5561', '5569', '6353', '6592',\n",
    "                    '8256', '8258', '8375', '8377', '8664', '5855']\n",
    "\n",
    "hadm_ids_w_transplants = diagnoses_icd[diagnoses_icd.icd_code.isin(TRANSPLANT_CODES)].hadm_id.unique()\n",
    "stay_ids_w_transplants = cohort[cohort.hadm_id.isin(hadm_ids_w_transplants)].stay_id.unique()\n",
    "kidney_df['transplant'] = 0\n",
    "transplant_indices = kidney_df[kidney_df.stay_id.isin(stay_ids_w_transplants)].index\n",
    "kidney_df.loc[transplant_indices, 'transplant'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.6488460103406"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_df[\"transplant\"].sum()/len(kidney_df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with LSTM layers\n",
    "\n",
    "We will treat this as a text classification problem, where each vital is a word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "TRAIN_COLS = ['anchor_age', 'patientweight', 'los', 'gender',\n",
    "       'alb', 'aniongap', 'bun', 'crp', 'ca', 'chloride', 'creatinine',\n",
    "       'fibrinogen', 'glucose', 'hgb', 'k', 'mg', 'na', 'p', 'platelets',\n",
    "       'troponin', 'wbc', 'apneainterval', 'artco2p', 'arto2p', 'expratio',\n",
    "       'hr', 'inspratio', 'insptime', 'nibpd', 'nibpm', 'nibps', 'pip', 'rr',\n",
    "       'spo2', 'temp', 'urine', 'vm', 'vt', 'betablockers', 'ca-iv',\n",
    "       'ca-noniv', 'cablockers', 'dextrose', 'fluids', 'insulin', 'k-iv',\n",
    "       'hours-k-iv', 'loopdiuretics', 'mg-iv', 'mg-noniv', 'hours-mg-noniv',\n",
    "       'p-iv', 'p-noniv', 'pnutrition', 'ponutrition', 'packedrbc',\n",
    "       'paralytics', 'sedation', 'tpnutrition', 'vasoactive', 'vasopressors',\n",
    "       'hours-p-iv']\n",
    "\n",
    "pred_var = 'transplant'\n",
    "\n",
    "X = kidney_df[TRAIN_COLS]\n",
    "X = X.fillna(-1)\n",
    "y = kidney_df[pred_var]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "x_t, X_val, y_t, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(x_t.shape[1], activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                  optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "model = get_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      " 78/106 [=====================>........] - ETA: 0s - loss: 1.0104 - accuracy: 0.9173WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30 batches). You may need to use the repeat() function when building your dataset.\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.0030 - accuracy: 0.9178 - val_loss: 0.9497 - val_accuracy: 0.9174\n",
      "Epoch 2/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.9469 - accuracy: 0.9172\n",
      "Epoch 3/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.9277 - accuracy: 0.9187\n",
      "Epoch 4/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.8575 - accuracy: 0.9167\n",
      "Epoch 5/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.7329 - accuracy: 0.9084\n",
      "Epoch 6/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.9034\n",
      "Epoch 7/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6596 - accuracy: 0.9040\n",
      "Epoch 8/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6451 - accuracy: 0.8990\n",
      "Epoch 9/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6683 - accuracy: 0.9123\n",
      "Epoch 10/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6173 - accuracy: 0.9138\n",
      "Epoch 11/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.9157\n",
      "Epoch 12/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.9135\n",
      "Epoch 13/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5324 - accuracy: 0.9169\n",
      "Epoch 14/20\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.9169\n",
      "Epoch 15/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.9130\n",
      "Epoch 16/20\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.9159\n",
      "Epoch 17/20\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.9123\n",
      "Epoch 18/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.9098\n",
      "Epoch 19/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.9142\n",
      "Epoch 20/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4189 - accuracy: 0.9113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1647ef390>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_t, y_t))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "model.fit(train_dataset, \n",
    "          epochs=20,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.1049808429118774\n",
      "Recall:  0.9288135593220339\n",
      "Accuracy 0.37196909139355183\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "preds = preds.flatten()\n",
    "\n",
    "# Binarize preds\n",
    "preds[preds <= 0] = 0\n",
    "preds[preds > 0] = 1\n",
    "\n",
    "correct_idx, = np.where(preds == y_test.values) \n",
    "incorrect_idx, = np.where(preds != y_test.values) \n",
    "correct = preds[correct_idx] \n",
    "incorrect = preds[incorrect_idx]\n",
    "tp = correct[correct == 1] # True positives\n",
    "fp = incorrect[incorrect == 1] # False positives\n",
    "\n",
    "tn = correct[correct == 0] # True negatives\n",
    "fn =  incorrect[incorrect == 0]# False negatives\n",
    "\n",
    "\n",
    "print(\"Precision: \", len(tp)/(len(tp) + len(fp)))\n",
    "print(\"Recall: \", len(tp)/(len(tp) + len(fn)))\n",
    "print(\"Accuracy\", len(correct) / (len(correct) + len(incorrect)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "TRAIN_COLS = ['anchor_age', 'patientweight', 'gender',\n",
    "       'alb', 'aniongap', 'bun', 'crp', 'ca', 'chloride', 'creatinine',\n",
    "       'fibrinogen', 'glucose', 'hgb', 'k', 'mg', 'na', 'p', 'platelets',\n",
    "       'troponin', 'wbc', 'apneainterval', 'artco2p', 'arto2p', 'expratio',\n",
    "       'hr', 'inspratio', 'insptime', 'nibpd', 'nibpm', 'nibps', 'pip', 'rr',\n",
    "       'spo2', 'temp', 'urine', 'vm', 'vt', 'betablockers', 'ca-iv',\n",
    "       'ca-noniv', 'cablockers', 'dextrose', 'fluids', 'insulin', 'k-iv',\n",
    "       'hours-k-iv', 'loopdiuretics', 'mg-iv', 'mg-noniv', 'hours-mg-noniv',\n",
    "       'p-iv', 'p-noniv', 'pnutrition', 'ponutrition', 'packedrbc',\n",
    "       'paralytics', 'sedation', 'tpnutrition', 'vasoactive', 'vasopressors',\n",
    "       'hours-p-iv',  'transplant']\n",
    "\n",
    "pred_var = 'los'\n",
    "\n",
    "X = kidney_df[TRAIN_COLS]\n",
    "X = X.fillna(-1)\n",
    "y = kidney_df[pred_var]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "x_t, X_val, y_t, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(len(x_t.columns), activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
    "                  loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "model = get_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      " 71/106 [===================>..........] - ETA: 0s - loss: 102.8524WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30 batches). You may need to use the repeat() function when building your dataset.\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 69.6596 - val_loss: 1.4158\n",
      "Epoch 2/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3989\n",
      "Epoch 3/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3975\n",
      "Epoch 4/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.4036\n",
      "Epoch 5/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3975\n",
      "Epoch 6/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3993\n",
      "Epoch 7/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3981\n",
      "Epoch 8/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3985\n",
      "Epoch 9/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3982\n",
      "Epoch 10/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3984\n",
      "Epoch 11/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3982\n",
      "Epoch 12/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3991\n",
      "Epoch 13/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3984\n",
      "Epoch 14/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3992\n",
      "Epoch 15/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3990\n",
      "Epoch 16/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3988\n",
      "Epoch 17/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3987\n",
      "Epoch 18/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3993\n",
      "Epoch 19/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3992\n",
      "Epoch 20/20\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.3989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16944fcc0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_t, y_t))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "model.fit(train_dataset, \n",
    "          epochs=20,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
